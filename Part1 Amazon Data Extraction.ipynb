{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the text to be searched : mobile\n",
      "Enter the no. of Pages to scrape (pages should be greater than 0 and less than 7 : 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Title : This script scrappes products data from amazon india website where you can search for any items\n",
    "\n",
    "\n",
    "'''\n",
    "Note: The script return product details only for those items where all fields have values, if any of the fiels is NONE it ingnores that product.\n",
    "It can be changed by using try and except for each required field.\n",
    "'''\n",
    "\n",
    "#Importing modules\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "class Amazon():\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''Steps followed to scrape the data:-\n",
    "          1. Amazon.Main function takes arguments search string and number of pages as integer to generates the final data.\n",
    "          2. Amazon.url function returns the web addresses of the pages\n",
    "          3. Amazon.html function returns the html contents of the urls\n",
    "          4. Amazon India webpage lists product in two different styles:\n",
    "            a. When product are listed in a horizontal list order (Sample url = https://www.amazon.in/s?k=men+shirts&ref=nb_sb_noss) Amazon.product_data1 function is used\n",
    "            b. When product are listed in vertical list order (Sample url : - https://www.amazon.in/s?k=laptops&ref=nb_sb_noss) Amazon.product_data2 function is used\n",
    "        \n",
    "         Note: Making requests to same page multiple times can lead to blocking of your ip from amazon webpage.\n",
    "           To avoid this a list of proxies can be used to make request using different ips, or there should be some time gap between making requests to same url.\n",
    "           For this uncomment the function get_free_proxies()\n",
    "      '''\n",
    "\n",
    "    def __init__(self, s, p):\n",
    "        self.search = s\n",
    "        self.page  = p\n",
    "            \n",
    "    def main(self):\n",
    "        urllist = self.url(self.search,self.page)\n",
    "        # contents = []\n",
    "        product_data ={}\n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "        for link in urllist:\n",
    "            content = self.html(link)\n",
    "            product_data,count1 = self.product_data1(content,count1,product_data)\n",
    "            if (not product_data) == True:\n",
    "                product_data,count2 = self.product_data2(content,count2,product_data) \n",
    "            else:\n",
    "                product_data,count1 = self.product_data1(content,count1,product_data)        \n",
    "            if (not product_data ) == True:\n",
    "                print(\"No information available. Try with a different search input.\")\n",
    "            else:\n",
    "                json_object = json.dumps(product_data, indent = 5)   \n",
    "        return json_object\n",
    "   \n",
    "    def url(self,search,page):\n",
    "        prefi_url = \"https://www.amazon.in/s?k=\"\n",
    "        suffix_url = \"&ref=nb_sb_noss\"\n",
    "        url_list = []\n",
    "        #initial page for scrapping\n",
    "        home_page = prefi_url+search.replace(' ','+')+suffix_url\n",
    "        url_list.append(home_page)\n",
    "        for i in range(1,int(page)+1):\n",
    "            #generating url for each page numbers\n",
    "            url1 = prefi_url+search.replace(' ','+')+'&page='+str(i)+suffix_url\n",
    "            url_list.append(url1)\n",
    "        return url_list\n",
    "    \n",
    "    \n",
    "#     def get_free_proxies(self):\n",
    "#         url = \"https://free-proxy-list.net/\"\n",
    "#         # get the HTTP response and construct soup object\n",
    "#         so = BeautifulSoup(requests.get(url).content, \"html.parser\")\n",
    "#         proxies = []\n",
    "#         for row in so.find(\"table\", attrs={\"id\": \"proxylisttable\"}).find_all(\"tr\")[1:]:\n",
    "#             tds = row.find_all(\"td\")\n",
    "#             try:\n",
    "#                 ip = tds[0].text.strip()\n",
    "#                 port = tds[1].text.strip()\n",
    "#                 host = f\"{ip}:{port}\"\n",
    "#                 proxies.append(host)\n",
    "#             except IndexError:\n",
    "#                 continue\n",
    "#         return proxies\n",
    "    \n",
    "    def html(self,url):\n",
    "        headers = {\"User-Agent\":\n",
    "                    \"Mozilla/5.0 (Windows NT 10.0; WOW64; rv:66.0)\"\n",
    "                    \" Gecko/20100101 Firefox/66.0\"}\n",
    "      \n",
    "    #         prox = self.get_free_proxies()\n",
    "#         session = requests.Session()\n",
    "#         proxy = random.choice(prox)\n",
    "#         session.proxies = {\"http\": proxy, \"https\": proxy}\n",
    "#         r = session.get(url,headers=headers)\n",
    "        try:\n",
    "            r = requests.get(url,headers=headers) \n",
    "            parsed = BeautifulSoup(r.content, features='lxml')\n",
    "        except:\n",
    "            pass\n",
    "        return parsed\n",
    "    \n",
    "    #Type 1 of Amazon Webpage\n",
    "    def product_data1(self,soup,count,product_details):\n",
    "        links = soup.findAll('div',attrs={'class':'a-section a-spacing-medium a-text-center'})\n",
    "        for i in range(len(links)):\n",
    "            count = count+1\n",
    "            try:\n",
    "                l = links[i].findAll('a')[0]['href']\n",
    "                #link of product\n",
    "                product_link = 'https://amazon.in'+l\n",
    "                \n",
    "                #product Title\n",
    "                product_title = links[i].find('span',attrs={'class':'a-size-base-plus a-color-base a-text-normal'}).get_text()\n",
    "#                 company \n",
    "\n",
    "                product_company = links[i].find('span',attrs={'class':'a-size-base-plus a-color-base'}).get_text()\n",
    "\n",
    "                    \n",
    "                prod_offer = links[i].find('span', attrs = {'class': 'a-letter-space'}).findNext('span').get_text()\n",
    "#                 prod_offer = prod_offer.split()[-1]\n",
    "                \n",
    "#                 #Product Image link\n",
    "                product_image_link = links[i].find('img')['src']\n",
    "                \n",
    "#                 #No of stars given to product\n",
    "                product_stars = links[i].find('a',attrs={'class':'a-popover-trigger a-declarative'}).get_text()\n",
    "                \n",
    "#                 #Price available \n",
    "                product_price = 'Rs'+links[i].find('span',attrs={'class':'a-price-whole'}).get_text()\n",
    "                product_price = product_price.replace('\\u20b9','Rs')\n",
    "\n",
    "                \n",
    "                #No. of reviews available\n",
    "                review_count = links[i].find('a',attrs={'class':'a-popover-trigger a-declarative'}).findNext('span').findNext('span').findNext('span').get_text()\n",
    "                #creating a dictionary for product details\n",
    "                details = {'Title' : product_title,\n",
    "                           'product_company': product_company,\n",
    "                            'Price' : product_price,\n",
    "                           'Product_offer': prod_offer,\n",
    "                            'prod_Stars' : product_stars,\n",
    "                            'No of reviews' : review_count,\n",
    "                           'product_Link' : product_link,\n",
    "                            'Image_link' : product_image_link,\n",
    "                  }\n",
    "                product_details[count] = details\n",
    "            except:\n",
    "                count = count-1\n",
    "                continue\n",
    "        return product_details,count\n",
    "\n",
    "    #Type 2 of Amazon Webpage\n",
    "    def product_data2(self,soup,count,product_details):\n",
    "        links = soup.findAll('div',attrs={'class':'s-main-slot s-result-list s-search-results sg-row'})\n",
    "        l = links[0].findAll('div',attrs={'class':'sg-col-inner'})\n",
    "        for i in range(len(l)):\n",
    "            count= count+1\n",
    "            try:\n",
    "                #product Link\n",
    "                prod_link = 'https://amazon.in'+l[i].find('span',attrs={'class':'rush-component'}).find('a')['href']\n",
    "                \n",
    "                #product Image Link\n",
    "                prod_img_link = l[i].find('span',attrs={'class':'rush-component'}).find('img')['src']\n",
    "                \n",
    "                #Product title\n",
    "                prod_title = l[i].find('span',attrs={'class':'a-size-medium a-color-base a-text-normal'}).get_text()\n",
    "                #   product_company\n",
    "                prod_company = l[i].find('span',attrs={'class':'a-size-medium a-color-base a-text-normal'}).get_text()\n",
    "                prod_company = prod_company.split()[0]\n",
    "                \n",
    "                #     product_offer\n",
    "                product_off = l[i].find('span', attrs = {'class': 'a-letter-space'}).findNext('span').get_text()\n",
    "#                 prod_offer = prod_offer.split()[-1]\n",
    "                \n",
    "#                 #product stars given\n",
    "                prod_stars = l[i].find('i').get_text()\n",
    "                \n",
    "#                 #No. of reviews\n",
    "                review_count = l[i].find('span',attrs={'class':'a-size-base'}).get_text()\n",
    "\n",
    "#                 #product Price\n",
    "                prod_price = l[i].find('span',attrs={'class':'a-price'}).findNext('span').get_text()\n",
    "                prod_price = prod_price.replace('\\u20b9','Rs')\n",
    "                \n",
    "\n",
    "                details = {'Title' : prod_title,\n",
    "                            \n",
    "                            'product_company' : prod_company,\n",
    "                            'Price' : prod_price,\n",
    "                            'Product_offer' : product_off,\n",
    "                            'prod_Stars' : prod_stars,\n",
    "                            'No of reviews' : review_count,\n",
    "                            'product_Link' : prod_link,\n",
    "                            'Image_link' : prod_img_link\n",
    "                        }\n",
    "                product_details[count] = details\n",
    "            except:\n",
    "                count = count-1\n",
    "                continue\n",
    "        return product_details,count\n",
    "    \n",
    "    \n",
    "#Search Input \n",
    "'''\n",
    "Sample search inputs:-\n",
    "    1. men  stylish shirts\n",
    "    2. Laptops under 30000\n",
    "    3. men sunglasses\n",
    "    4. smartphones under 10000\n",
    "'''\n",
    "\n",
    "search_text = input(\"Enter the text to be searched : \")\n",
    "no_page = input(\"Enter the no. of Pages to scrape (pages should be greater than 0 and less than 7 : \")\n",
    "\n",
    "# search_text ='water heater'\n",
    "# no_page = 30\n",
    "\n",
    "#Since for most of the product listed in horizontal view has max no. of 7 pages so providing a upper limit of 7 pages\n",
    "\n",
    "if (int(no_page)>0 and int(no_page)<=30):\n",
    "    sample = Amazon(search_text,no_page)\n",
    "    data = sample.main()\n",
    "else:\n",
    "    print(\"Try again Page index error\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>product_company</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product_offer</th>\n",
       "      <th>prod_Stars</th>\n",
       "      <th>No of reviews</th>\n",
       "      <th>product_Link</th>\n",
       "      <th>Image_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OPPO A31 (Mystery Black, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>OPPO</td>\n",
       "      <td>Rs12,990</td>\n",
       "      <td>Save ₹3,000 (19%)</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>44,909</td>\n",
       "      <td>https://amazon.in/Oppo-Mystery-Storage-Additio...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71KCwNV6Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Redmi 9 Activ (Coral Green, 4GB RAM, 64GB Stor...</td>\n",
       "      <td>Redmi</td>\n",
       "      <td>Rs9,499</td>\n",
       "      <td>Save ₹1,483 (14%)</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>136,536</td>\n",
       "      <td>https://amazon.in/Redmi-Activ-Coral-Green-Stor...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/91kAtEXPIe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Redmi 9 Activ (Carbon Black, 6GB RAM, 128GB St...</td>\n",
       "      <td>Redmi</td>\n",
       "      <td>Rs11,499</td>\n",
       "      <td>Save ₹1,500 (12%)</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>136,536</td>\n",
       "      <td>https://amazon.in/Redmi-Activ-Carbon-Black-Sto...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/911TJ1CDbL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Redmi 9A (Nature Green, 3GB Ram, 32GB Storage)...</td>\n",
       "      <td>Redmi</td>\n",
       "      <td>Rs8,299</td>\n",
       "      <td>Save ₹1,200 (13%)</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>138,914</td>\n",
       "      <td>https://amazon.in/Redmi-9A-3GB-32GB-Storage/dp...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OPPO A74 5G (Fluid Black,6GB RAM,128GB Storage...</td>\n",
       "      <td>OPPO</td>\n",
       "      <td>Rs16,990</td>\n",
       "      <td>Save ₹4,000 (19%)</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>20,221</td>\n",
       "      <td>https://amazon.in/OPPO-Fluid-Black-128GB-Stora...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71poFSdDs5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title product_company  \\\n",
       "1  OPPO A31 (Mystery Black, 6GB RAM, 128GB Storag...            OPPO   \n",
       "2  Redmi 9 Activ (Coral Green, 4GB RAM, 64GB Stor...           Redmi   \n",
       "3  Redmi 9 Activ (Carbon Black, 6GB RAM, 128GB St...           Redmi   \n",
       "4  Redmi 9A (Nature Green, 3GB Ram, 32GB Storage)...           Redmi   \n",
       "5  OPPO A74 5G (Fluid Black,6GB RAM,128GB Storage...            OPPO   \n",
       "\n",
       "      Price      Product_offer          prod_Stars No of reviews  \\\n",
       "1  Rs12,990  Save ₹3,000 (19%)  4.2 out of 5 stars        44,909   \n",
       "2   Rs9,499  Save ₹1,483 (14%)  4.2 out of 5 stars       136,536   \n",
       "3  Rs11,499  Save ₹1,500 (12%)  4.2 out of 5 stars       136,536   \n",
       "4   Rs8,299  Save ₹1,200 (13%)  4.2 out of 5 stars       138,914   \n",
       "5  Rs16,990  Save ₹4,000 (19%)  4.2 out of 5 stars        20,221   \n",
       "\n",
       "                                        product_Link  \\\n",
       "1  https://amazon.in/Oppo-Mystery-Storage-Additio...   \n",
       "2  https://amazon.in/Redmi-Activ-Coral-Green-Stor...   \n",
       "3  https://amazon.in/Redmi-Activ-Carbon-Black-Sto...   \n",
       "4  https://amazon.in/Redmi-9A-3GB-32GB-Storage/dp...   \n",
       "5  https://amazon.in/OPPO-Fluid-Black-128GB-Stora...   \n",
       "\n",
       "                                          Image_link  \n",
       "1  https://m.media-amazon.com/images/I/71KCwNV6Mu...  \n",
       "2  https://m.media-amazon.com/images/I/91kAtEXPIe...  \n",
       "3  https://m.media-amazon.com/images/I/911TJ1CDbL...  \n",
       "4  https://m.media-amazon.com/images/I/71sxlhYhKW...  \n",
       "5  https://m.media-amazon.com/images/I/71poFSdDs5...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df = json.loads(data)\n",
    "df = pd.DataFrame.from_dict(df)\n",
    "df = df.transpose()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
